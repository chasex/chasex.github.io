<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Go on Chasex&#39;s Blog</title>
    <link>http://chasex.github.io/tags/go/</link>
    <description>Recent content in Go on Chasex&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Dec 2015 20:30:00 +0200</lastBuildDate>
    <atom:link href="http://chasex.github.io/tags/go/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>GOPL-Go语言编程&#34;圣经&#34;</title>
      <link>http://chasex.github.io/2015/12/30/gopl-go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E5%9C%A3%E7%BB%8F</link>
      <pubDate>Wed, 30 Dec 2015 20:30:00 +0200</pubDate>
      
      <guid>http://chasex.github.io/2015/12/30/gopl-go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E5%9C%A3%E7%BB%8F</guid>
      <description>&lt;p&gt;花了一个月的时间，断断续续终于把&lt;code&gt;The Go Programming Language(GOPL)&lt;/code&gt;看完了。至于
读后感，用一句话来总结，大概就是：”这是一本注定要成为Go语言编程圣经的书。“&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://chasex.github.io/images/cover.png&#34; width=&#34;400&#34; height=&#34;496&#34; title=&#34;The Go Programming Language&#34; alt=&#34;The Go Programming Language&#34;&gt;&lt;/p&gt;

&lt;p&gt;全书内容从基本数据类型讲起，过渡到函数、接口等OOP编程相关，然后深入并发控制、通信
与同步等进阶话题，再到构建系统、测试框架，最后以反射、低阶编程等高级话题结束，编排
合理，文笔简练。GOPL基本覆盖到了Go的全貌，对发展历史、语言特性、运行机制等各个方面
都作了深入浅出的阐述。全书提供了大量的代码实例，不仅比官网的交互教程更加深入，而且比枯燥的
Language Specification更加生动。书中甚至还花了大量的篇幅介绍Go项目管理，如包管理、
构建系统、文档、测试框架(单元测试、代码覆盖率&amp;hellip;)、profiling等，这些内容在同类型的
书是比较少见的。&lt;/p&gt;

&lt;p&gt;提起本书的两位作者，可谓大有来头。作者之一的Brian Kernighan，曾与Ken Thompson
和Dennis Ritchie同在Bell Labs共事，UNIX的早期贡献者。他是awk发明者之一，还是世界上第一个写出
Hello World程序的人。他与Ritchie合著的&lt;code&gt;The C Programming Language&lt;/code&gt;，被誉为C语言编程
的&amp;rdquo;圣经&amp;rdquo;。另一作者Alan Donovan，是Google的Go开发组成员，参与开发了诸多标准库，以及
多个静态分析工具，如oracle, doc, rename等。再看看本书的审校，Rob Pike和Russ Cox两位Go的设计者，
加上其他核心开发组成员，阵容可谓空前强大。&lt;/p&gt;

&lt;p&gt;如果我们追溯一下Go的历史，会发现一个很重要的项目——&lt;a href=&#34;http://plan9.bell-labs.com/plan9/&#34;&gt;Plan 9&lt;/a&gt;。
这是Rob Pike和Russ Cox在Bell Labs开发的分布式操作系统，它借鉴了UNIX的设计思想，将所有的硬件资源都
抽象成统一的文件形式。通过一个称为9P的网络协议，把许多节点联结成一个集群，并允许各个节点像本地一样调度
全局资源(是不是很像GFS？)。Plan 9项目是一个伟大的构想，它比Google在2006年以后掀起的分布式计算浪潮
整整领先了15年，而且做得更彻底，直接在系统层面实现分布式。但是，这样一个项目，从1992年第一个发布，
到2002年最后一次发布，此后的十几年间再无动静。随着AT&amp;amp;T公司在2000年左右动荡，分拆再分拆，Bell Labs
几易其主后逐渐衰微，人才凋零。Plan 9项目也不能幸免，无人开发维护，至今前途未卜，实在令人不胜唏嘘。&lt;/p&gt;

&lt;p&gt;Go脱胎于Plan 9项目，用户态线程(goroutine)的设计，非常适合应用于存在大量网络通信的分布式系统。
随着网络的发展，高并发、低延迟、大数据等要求，使得计算机系统从单机向集群进化，从集中式走向分布式。
相信Go以其强静态、高效、并发等诸多优点，未来会在各个领域发挥重要作用。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>浅谈并发模型</title>
      <link>http://chasex.github.io/2015/12/16/%E6%B5%85%E8%B0%88%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B</link>
      <pubDate>Wed, 16 Dec 2015 21:06:32 +0800</pubDate>
      
      <guid>http://chasex.github.io/2015/12/16/%E6%B5%85%E8%B0%88%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B</guid>
      <description>

&lt;p&gt;随着网络的发展，互联网在线用户迅猛增长，单台服务器处理的连接数也急剧升高。从1999
年Dan Kegel提出著名的&lt;a href=&#34;https://en.wikipedia.org/wiki/C10k_problem&#34;&gt;C10K&lt;/a&gt;问题，到
2010年WhatsApp单机突破200万连接，短短的20年间服务器并发数提高了200倍。这对服务端
的并发编程提出了更高的要求，那么常见的并发模型有哪些呢？&lt;/p&gt;

&lt;h3 id=&#34;进程:a8489f7c1a3fada3714960b0ee39e5cb&#34;&gt;进程&lt;/h3&gt;

&lt;p&gt;进程(Process)是通常是我们接触到的第一种并发模型，它是操作资源分配、调度的最小单位。
进程有程序执行所需的一切资源，包括独立的地址空间、可执行的代码段、打开的文件句柄、
堆、栈等等。&lt;/p&gt;

&lt;p&gt;进程并发模型最大的优点就是简单。进程一次只处理一个连接，处理完毕后阻塞等待下一个连接。
进程间通过(有名)管道，消息队列，共享内存、UNIX域套接字等IPC通信。由于进程地址空间独立，不存在资源竞争，
所以不必考虑同步、死锁等问题。而且，一个进程的崩溃不会影响其他进程的执行，可靠性较高。&lt;/p&gt;

&lt;p&gt;但是，进程是所有并发模型中效率最低的。我们知道进程调度是抢占式的(preemptive schedule)，
当系统调用阻塞或进程的时间片用完后，调度器将其从CPU移走，选择另一个进程执行。
这中间涉及到上下文切换(context switch)，即将原有进程的所有抽象和资源切换为新进程所属资源。
因此，进程切换的开销主要来自于(1)用户空间与内核空间转化，(2)任务调度器的计算复杂度，
(3)进程上下文切换。其中，又以进程上下文切换最为耗时。&lt;/p&gt;

&lt;p&gt;通常，一个进程的上下文包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通用寄存器、状态寄存器、程序计数器等各种CPU寄存器&lt;/li&gt;
&lt;li&gt;内核栈、用户栈&lt;/li&gt;
&lt;li&gt;page table, 用于虚拟地址空间和物理地址空间映射&lt;/li&gt;
&lt;li&gt;process table，保存进程id，优先级，环境变量等&lt;/li&gt;
&lt;li&gt;file table，保存当前进程打开文件的状态信息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在一些架构中，上下文切换甚至包括各种处理器缓存的刷新，这些缓存无法在进程间共享。
比如，x86架构会刷新快表(TLB)，而ARM架构甚至会刷新一级缓存(L1 cache)。&lt;/p&gt;

&lt;p&gt;最典型的采用进程模型的服务是Apache，它使用了prefork来减少进程创建的开销。&lt;/p&gt;

&lt;h3 id=&#34;线程:a8489f7c1a3fada3714960b0ee39e5cb&#34;&gt;线程&lt;/h3&gt;

&lt;p&gt;线程(Thread)是运行在进程内的逻辑流(logical flow)。一个进程内可以有多个并发执行的线程，
这些线程由内核进行自动调度。线程实现在不同系统可能有所不同，例如在Windows和Solaris中，
线程和进程在内核中有不同的数据结构标识，因此调度方式也不同。在Linux系统中，线程与进程
在内核具有一致的数据抽象，使用task_struct标识，由任务调度器&lt;a href=&#34;http://www.ibm.com/developerworks/library/l-completely-fair-scheduler/&#34;&gt;CFS&lt;/a&gt;进行统一调度。&lt;/p&gt;

&lt;p&gt;线程并发模型相对于进程模型来说，上下文切换的开销要小很多。由于共享地址空间，&lt;strong&gt;同一个进程&lt;/strong&gt;
的不同线程切换时，只需切换CPU中的各种寄存器，而不必进行昂贵的地址转换、缓存刷新操作。
寄存器的切换是非常高效的，通常，它的开销与一次内核态、用户态的切换相当。此外，线程间不需要
低效的IPC通信，可以访问共享的地址空间。由于线程独立顺序执行，具有较好的数据局部性(data locality)。&lt;/p&gt;

&lt;p&gt;但是，正如Fred Brooks所说的“软件工程没有银弹”，共享地址空间减少线程切换的开销的同时，
也带来了额外的问题。多个线程可能同时操作同一副本，造成数据冲突，从而带来不可预期结果；
或者线程间互相依赖，一个线程阻塞，等待另一个线程的执行结果。前者称为互斥，后者称为同步，为了进行线程间
的互斥和同步，引入了原子操作、锁、条件变量、信号量等机制。要正确使用这些机制不是一件简单
的事，如果使用不当，可能造成死锁，如果滥用，还可能带来性能损失。此外，多线程的调试也不是特别方便。&lt;/p&gt;

&lt;p&gt;在现代SMP系统中，多核多CPU的出现，给内核任务调度器带来更大的挑战。若线程跨核心跨物理CPU调度，
会触发所谓的&lt;a href=&#34;https://cseweb.ucsd.edu/~rstrong/publications/osr09preprint.pdf&#34;&gt;core switch&lt;/a&gt;，迁移当前线程的工作状态。
根据Google的一项&lt;a href=&#34;https://www.youtube.com/watch?v=KXuZi9aeGTw&#34;&gt;研究显示&lt;/a&gt;，用户态与内核态的切换约为50ns，而一次典型的线程切换约为2.7us。
如果开启CPU Affinity，将每个进程绑定在特定的核心，能降至1us左右，但是这在实际系统中难以操作。&lt;/p&gt;

&lt;p&gt;典型的采用线程模型的服务有Apache-MPM、Tomcat。&lt;/p&gt;

&lt;h3 id=&#34;io多路复用:a8489f7c1a3fada3714960b0ee39e5cb&#34;&gt;IO多路复用&lt;/h3&gt;

&lt;p&gt;IO多路复用(IO Multiplexing)也称为事件驱动(event driven)模型，它将程序执行的逻辑流
刻画为状态机。状态机由当前状态、输入事件，以及事件与状态转化的映射构成。具体来说，
通过select/epoll/kqueue等系统调用同时监听多个句柄，根据每个句柄触发的事件执行
相应的回调函数。这些事件包括可读、可写、出错，句柄可以是网络套接字，也可以是本地管道、文件描述符。&lt;/p&gt;

&lt;p&gt;IO多路复用避免了读写阻塞，大幅提升了吞吐率和CPU利用率。除了轮询系统调用，所有的并发控制都是用户空间完成的，
没有上下文切换开销，效率非常高。IO复用运行在单个进程中，多个并发流很容易共享数据，
不需要IPC通信。没有竞态条件(race condition)，也不需要锁、条件变量等同步机制。&lt;/p&gt;

&lt;p&gt;IO多路复用的缺点同样很明显。首先，它将原本线性的处理流程变成事件驱动的状态机，一次请求可能有多种中间状态，
每种状态执行不同回调函数。这种异步、非线性的模型，极大地增加了编程难度（如果有兴趣，可以浏览一下&lt;a href=&#34;http://nginx.org/en/download.html&#34;&gt;Nginx&lt;/a&gt;源码，
那满屏的回调函数一定会令你印象深刻）。即使现在有框架的帮助，如libevent，libev，libuv等，
有经验的程序员也必须小心翼翼才能不犯错。其次，由于单进程执行，IO复用无法充分发挥多核CPU的优势，所有并发都是串行执行的。
在CPU普遍16、20核的今天，这显然令人无法接受。由于串行执行，在回调中任何阻塞操作都将显著影响性能，最好是将这些操作也异步执行。
但是，在使用一些封装好的客户端，如zookeeper client，redis client时，很难将其注册到epoll等轮询调用中。&lt;/p&gt;

&lt;p&gt;典型的采用IO复用模型的服务有Nginx，Redis，Tornado等。&lt;/p&gt;

&lt;h3 id=&#34;协程:a8489f7c1a3fada3714960b0ee39e5cb&#34;&gt;协程&lt;/h3&gt;

&lt;p&gt;协程(Coroutine)也称为用户态线程(User-Space Thread)，是一种协同的、非抢占式的多任务并发模型。
协程运行在用户空间，当遇到阻塞或特定入口时，通过显式调用切换方法主动让出CPU，由任务调度器选取另一个协程执行。
通常，协程切换只是简单地改变执行函数栈，不涉及内核态与用户态转化，也涉及上下文切换，开销远小于进程/线程切换。&lt;/p&gt;

&lt;p&gt;协程的使用没有前三个并发模型那么广泛，一方面是因为是它缺少系统、语言层面的支持，如C/C++/Java并不支持原生的协程。
另一方面，是因为协程比较晦涩，不如进程、线程、IO复用等并发模型直观。其实，协程的历史很早，1958年Melvin Conway
第一次在汇编语言引入协程。之后，从上世纪六七十年代的Simula、Modula-2、Scheme，到我们熟知的Python、Ruby、C#等，
都有协程的身影。近几年，典型的支持协程的语言有Lua、Go、Rust、Scala等，下面以Go为例简要介绍一下协程并发模型。&lt;/p&gt;

&lt;p&gt;在Go中，协程被称为goroutine，它与线程的第一个区别是其创建的开销非常小。操作系统为每个创建的线程
分配一个固定大小的栈(一般为2MB)，栈上存储所有挂起或正在执行的函数及其局部变量。2MB的栈空间对于简单的任务
来说显得太浪费，而对于一些复杂的任务（如深度嵌套的递归）来说又显得太小。因此，goroutine的栈采取了动态扩容方式，
初始时仅为2KB，随着任务执行按需增长，最大可达1GB。此外，GC还会周期性地将不再使用的内存回收，收缩栈空间。
通常，Go程序可以同时并发成百上千个协程，这都得益于它高效的内存模型。&lt;/p&gt;

&lt;p&gt;goroutine与线程的第二个区别是其调度的开销非常小。前面我们说过，线程切换是由内核调度器执行的，涉及到用户态/内核态的转化、上线文切换，
而Go有自己的runtime调度器，负责goroutine调度。Go调度器不是由硬件时钟中断周期性触发，而是在程序执行的特殊点发生。这些点包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;系统调用阻塞，如磁盘、网络IO&lt;/li&gt;
&lt;li&gt;新的goroutine被创建&lt;/li&gt;
&lt;li&gt;通道(channel)发送、接收阻塞&lt;/li&gt;
&lt;li&gt;GC执行周期结束&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;goroutine在运行过程中遇到这些点时，会主动让出CPU，由调度器选择另一个执行（通常，只是简单地交换栈指针）。
由于调度器工作在用户空间，没有用户态/内核态转化、上下文切换，所以goroutine切换的开销比线程小很多。&lt;/p&gt;

&lt;p&gt;此外，为了充分发挥多核性能，Go采用了M:N的调度模型，即M个协程工作在N个线程上。调度器负责将协程分配给某个线程执行，并尽量保证并行执行。
当一个线程没有可执行协程时，调度器会从全局的协程队列分配。当全局队列也没有时，调度器甚至会从其他线程&amp;rdquo;偷&amp;rdquo;一些过来(Work-Stealing)。&lt;/p&gt;

&lt;p&gt;典型的采用协程模型的服务有openresty(Lua), gevent(Python), http server(Go)。&lt;/p&gt;

&lt;h3 id=&#34;总结:a8489f7c1a3fada3714960b0ee39e5cb&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;以上总结了目前4种常用的并发模型，它们在工作原理、运行效率、编程难度等方面有显著区别，各自有适用场景，在实际使用时应该根据需求仔细评估。
通常，在大型系统构建过程中，不会只用到某种单一的并发模型，而是两种甚至是三种联合工作。例如，Apache-MPM是多进程加线程池的模型，Nginx是多进程加IO
复用的模型，某些半同步半异步(Half-sync/Half-async)的服务是IO复用加线程池的模型，而协程调度器底层实现也离不开线程、IO复用的支持。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Go Receiver的隐式转化</title>
      <link>http://chasex.github.io/2015/12/02/go-receiver%E7%9A%84%E9%9A%90%E5%BC%8F%E8%BD%AC%E5%8C%96</link>
      <pubDate>Wed, 02 Dec 2015 22:45:43 +0200</pubDate>
      
      <guid>http://chasex.github.io/2015/12/02/go-receiver%E7%9A%84%E9%9A%90%E5%BC%8F%E8%BD%AC%E5%8C%96</guid>
      <description>&lt;p&gt;最近在读&lt;code&gt;The Go Programming Language&lt;/code&gt;，第6章提到了method receiver的隐式转化。
这是初学Go比较令人困惑的地方，之前做项目也有犯类似错误，故在此归纳记录一下。&lt;/p&gt;

&lt;p&gt;在Go中method的receiver要么是自定义类型，要么是指向自定义类型的指针。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;type Point struct {
    X, Y float64
}

func (p Point) Distance() float64 {
    return math.Hypot(p.X, p.Y)    
}

func (p *Point) Scale(factor float64) {
    p.X *= factor    
    p.Y *= factor
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Go允许T类型的变量调用receiver为*T的方法，编译器隐式地对变量做了取地址操作。
同样地，也允许*T类型的变量调用receiver为T的方法，编译器隐式地对指针做了解引用操作。
这是一个很好用的语法糖，使得我们在编码时不用做显式类型转化。
但是要注意，对于临时变量，由于无法获取地址，Go不会做隐式的转化。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;func main() {
    p := Point{3, 4}

    p.Distance()
    p.Scale(2)          // implicit (&amp;amp;p)
    fmt.Println(p)      // {6, 8}

    q := &amp;amp;Point{3, 4}
    q.Distance()        // implicit (*q)
    q.Scale(2)          
    fmt.Println(q)      // &amp;amp;{6, 8}
    
    Point{3, 4}.Scale(2) // compile error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么这种转化是否适用于interface呢？让我们来看一个例子。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;type Interface interface {
    String() string
    Set(s string)
}

type Message struct {
    msg string
}

func (s Message) String() string {
    return &amp;quot;Message: &amp;quot; + s.msg
}

func (s *Message) Set(msg string) {
    s.msg = msg
}

func main() {
    m1 := Message{&amp;quot;hello world&amp;quot;}
    m2 := &amp;amp;Message{&amp;quot;hello world&amp;quot;}

    m1.String()
    m1.Set(&amp;quot;new message&amp;quot;)

    m2.String()
    m2.Set(&amp;quot;new message&amp;quot;)

    var _ Interface = m1    // compile error
    var _ Interface = m2
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在这个例子中，为Message定义了一个String方法，为*Message类型定义了一个Set方法。
Message类型的变量m1能调用String和Set方法，但是不满足Interface接口，编译器提示
Set方法缺失。反之，*Message类型的变量m2既能调用String和Set方法，同时也满足
Interface接口。&lt;/p&gt;

&lt;p&gt;可见，T类型不会自动拥有以*T作为receiver的方法，而*T类型却会自动拥有以T作为recevier
的所有方法。这该如何理解呢？其实很好理解，当一个方法以*T作为receiver时，
这个方法可能会改变变量的值。如果将它应用于T，改变的只是变量的副本，
而对原值没有影响，从而造成非预期结果。当一个方法以T作为receiver时，我们预期它不会改变变量的值，将它应用于*T也不会有任何负面影响，因此编译器会为我们自动生成一个以*T作为receiver的版本。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>